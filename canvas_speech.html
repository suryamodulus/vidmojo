<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,minimum-scale=1.0, user-scalable=no">

    <title>Canvas2D + Mp3 Recording using RecordRTC</title>    
    <meta name="description" content="Record canvas animation using RecordRTC.">
    <meta name="author" content="Muaz Khan"><link rel="author" type="text/html" href="https://plus.google.com/100325991024054712503">
    <!-- <script src="https://code.responsivevoice.org/responsivevoice.js?key=91cYdino"></script> -->
    <!-- <script type="text/javascript" src="https://unpkg.com/speech-synthesis-recorder@1.2.1/SpeechSynthesisRecorder.js"></script> -->
</head>
    <body>

    <button id="btn-record-webm">Play Audio</button>

    <script>
        //SpeechSynthesisRecorder.js guest271314 6-17-2017
        // Motivation: Get audio output from `window.speechSynthesis.speak()` call
        // https://github.com/guest271314/SpeechSynthesisRecorder

        class SpeechSynthesisRecorder {
            constructor({text = "", utteranceOptions = {}, recorderOptions = {}, dataType = ""}) {
                if (text === "") throw new Error("no words to synthesize");
                this.dataType = dataType;
                this.text = text;
                this.mimeType = MediaRecorder.isTypeSupported("audio/webm; codecs=opus") 
                                ? "audio/webm; codecs=opus" : "audio/ogg; codecs=opus";
                this.utterance = new SpeechSynthesisUtterance(this.text);
                this.speechSynthesis = window.speechSynthesis;
                this.mediaStream_ = new MediaStream();
                this.mediaSource_ = new MediaSource();
                this.mediaRecorder = new MediaRecorder(this.mediaStream_, {
                    mimeType: this.mimeType,
                    bitsPerSecond: 256 * 8 * 1024
                });
                this.audioContext = new AudioContext();
                this.audioNode = new Audio();
                this.chunks = Array();
                if (utteranceOptions) {
                    if (utteranceOptions.voice) {
                        this.speechSynthesis.onvoiceschanged = e => {
                        const voice = this.speechSynthesis.getVoices().find(({
                            name: _name
                        }) => _name === utteranceOptions.voice);
                        this.utterance.voice = voice;
                        console.log(voice, this.utterance);
                        }
                        this.speechSynthesis.getVoices();
                    }
                    var {
                        lang, rate, pitch
                    } = utteranceOptions;
                    Object.assign(this.utterance, {
                        lang, rate, pitch
                    });
                }
                this.audioNode.controls = "controls";
                document.body.appendChild(this.audioNode);
            }
            start(text = "") {
                if (text) this.text = text;
                if (this.text === "") throw new Error("no words to synthesize");
                return navigator.mediaDevices.getUserMedia({
                    audio: true
                })
                .then(stream => new Promise(resolve => {
                    const track = stream.getAudioTracks()[0];
                    this.mediaStream_.addTrack(track);
                    // return the current `MediaStream`
                    if (this.dataType && this.dataType === "mediaStream") {
                        resolve({tts:this, data:this.mediaStream_});
                    };
                    this.mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            this.chunks.push(event.data);
                        };
                    };
                    this.mediaRecorder.onstop = () => {
                        track.stop();
                        this.mediaStream_.getAudioTracks()[0].stop();
                        this.mediaStream_.removeTrack(track);
                        console.log(`Completed recording ${this.utterance.text}`, this.chunks);
                        resolve(this);
                    }
                    this.mediaRecorder.start();
                    this.utterance.onstart = () => {
                        console.log(`Starting recording SpeechSynthesisUtterance ${this.utterance.text}`);
                    }
                    this.utterance.onend = () => {
                        this.mediaRecorder.stop();
                        console.log(`Ending recording SpeechSynthesisUtterance ${this.utterance.text}`);
                    }
                    this.speechSynthesis.speak(this.utterance);
                }));
            }
        }
    
    </script>

    <script>
        (function () {
            var lastTime = 0, vendors = ['ms', 'moz', 'webkit', 'o'];
            for (var x = 0; x < vendors.length && !window.requestAnimationFrame; ++x) {
                window.requestAnimationFrame = window[vendors[x] + 'RequestAnimationFrame'];
                window.cancelAnimationFrame = window[vendors[x] + 'CancelAnimationFrame'] || window[vendors[x] + 'RequestCancelAnimationFrame'];
            }
            if (!window.requestAnimationFrame)
                window.requestAnimationFrame = function (callback, element) {
                    var currTime = new Date().getTime();
                    var timeToCall = Math.max(0, 16 - (currTime - lastTime));
                    var id = window.setTimeout(function () {
                        callback(currTime + timeToCall);
                    }, timeToCall);
                    lastTime = currTime + timeToCall;
                    return id;
                };
            if (!window.cancelAnimationFrame)
                window.cancelAnimationFrame = function (id) {
                    clearTimeout(id);
                };
        }());
    </script>

    <!-- below section handles RecordRTC and WhammyRecorder -->

    <script src="https://www.webrtc-experiment.com/RecordRTC.js"></script>

    <script>

        
        document.getElementById('btn-record-webm').onclick = function() {
            
            getMp3Stream(function(audioStream, tts){
                var recorder = RecordRTC(audioStream, {
                    type: 'audio',
                    mimeType: 'audio/webm',
                });

                recorder.startRecording();

                tts.utterance.onend = () => {
                    recorder.stopRecording(function() {
                        recorder.save("canvas_speech.webm")
                    });
                }
            })
        };

        function getMp3Stream(callback) {
            var ttsRecorder = new SpeechSynthesisRecorder({
                text: "The revolution will not be televised", 
                utteranceOptions: {
                    voice: "english-us espeak",
                    lang: "en-US",
                    pitch: .75,
                    rate: parseFloat(1)
                }, 
                dataType:"mediaStream"
            });
            ttsRecorder.start()
            .then(({tts, data}) => {
                callback(data, tts)
            })
            .catch(err => console.log(err))
            // responsiveVoice.speak("Hello")
            // responsiveVoice.speak("hello world", "UK English Male");
        };
    </script>
</body>
</html>